{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e8079cf-6a88-4f27-bcca-83fd70a4dcd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "CHUNK_SIZE = 1024\n",
    "voice_id = \"hDDJRL9aTI0hbD6crp4v\"\n",
    "url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}\"\n",
    "XI_API_KEY = \"7b9879f9e2b120bea4cf089b2ae47ef4\"\n",
    "\n",
    "headers = {\n",
    "  \"Accept\": \"audio/mpeg\",\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"xi-api-key\": XI_API_KEY\n",
    "}\n",
    "\n",
    "data = {\n",
    "  \"text\": \"Hi! My name is Bella, nice to meet you!\",\n",
    "  \"model_id\": \"eleven_monolingual_v1\",\n",
    "  \"voice_settings\": {\n",
    "    \"stability\": 0.5,\n",
    "    \"similarity_boost\": 0.5\n",
    "  }\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "with open('output.mp3', 'wb') as f:\n",
    "    for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "742025e8-ccdc-496c-b102-562233dfa231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Response in module requests.models object:\n",
      "\n",
      "class Response(builtins.object)\n",
      " |  The :class:`Response <Response>` object, which contains a\n",
      " |  server's response to an HTTP request.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |      Returns True if :attr:`status_code` is less than 400.\n",
      " |      \n",
      " |      This attribute checks if the status code of the response is between\n",
      " |      400 and 600 to see if there was a client error or a server error. If\n",
      " |      the status code, is between 200 and 400, this will return True. This\n",
      " |      is **not** a check to see if the response code is ``200 OK``.\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |  \n",
      " |  __exit__(self, *args)\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __init__(self)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Allows you to use a response as an iterator.\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |      Returns True if :attr:`status_code` is less than 400.\n",
      " |      \n",
      " |      This attribute checks if the status code of the response is between\n",
      " |      400 and 600 to see if there was a client error or a server error. If\n",
      " |      the status code, is between 200 and 400, this will return True. This\n",
      " |      is **not** a check to see if the response code is ``200 OK``.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  close(self)\n",
      " |      Releases the connection back to the pool. Once this method has been\n",
      " |      called the underlying ``raw`` object must not be accessed again.\n",
      " |      \n",
      " |      *Note: Should not normally need to be called explicitly.*\n",
      " |  \n",
      " |  iter_content(self, chunk_size=1, decode_unicode=False)\n",
      " |      Iterates over the response data.  When stream=True is set on the\n",
      " |      request, this avoids reading the content at once into memory for\n",
      " |      large responses.  The chunk size is the number of bytes it should\n",
      " |      read into memory.  This is not necessarily the length of each item\n",
      " |      returned as decoding can take place.\n",
      " |      \n",
      " |      chunk_size must be of type int or None. A value of None will\n",
      " |      function differently depending on the value of `stream`.\n",
      " |      stream=True will read data as it arrives in whatever size the\n",
      " |      chunks are received. If stream=False, data is returned as\n",
      " |      a single chunk.\n",
      " |      \n",
      " |      If decode_unicode is True, content will be decoded using the best\n",
      " |      available encoding based on the response.\n",
      " |  \n",
      " |  iter_lines(self, chunk_size=512, decode_unicode=False, delimiter=None)\n",
      " |      Iterates over the response data, one line at a time.  When\n",
      " |      stream=True is set on the request, this avoids reading the\n",
      " |      content at once into memory for large responses.\n",
      " |      \n",
      " |      .. note:: This method is not reentrant safe.\n",
      " |  \n",
      " |  json(self, **kwargs)\n",
      " |      Returns the json-encoded content of a response, if any.\n",
      " |      \n",
      " |      :param \\*\\*kwargs: Optional arguments that ``json.loads`` takes.\n",
      " |      :raises ValueError: If the response body does not contain valid json.\n",
      " |  \n",
      " |  raise_for_status(self)\n",
      " |      Raises stored :class:`HTTPError`, if one occurred.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  apparent_encoding\n",
      " |      The apparent encoding, provided by the chardet library.\n",
      " |  \n",
      " |  content\n",
      " |      Content of the response, in bytes.\n",
      " |  \n",
      " |  is_permanent_redirect\n",
      " |      True if this Response one of the permanent versions of redirect.\n",
      " |  \n",
      " |  is_redirect\n",
      " |      True if this Response is a well-formed HTTP redirect that could have\n",
      " |      been processed automatically (by :meth:`Session.resolve_redirects`).\n",
      " |  \n",
      " |  links\n",
      " |      Returns the parsed header links of the response, if any.\n",
      " |  \n",
      " |  next\n",
      " |      Returns a PreparedRequest for the next request in a redirect chain, if there is one.\n",
      " |  \n",
      " |  ok\n",
      " |      Returns True if :attr:`status_code` is less than 400, False if not.\n",
      " |      \n",
      " |      This attribute checks if the status code of the response is between\n",
      " |      400 and 600 to see if there was a client error or a server error. If\n",
      " |      the status code is between 200 and 400, this will return True. This\n",
      " |      is **not** a check to see if the response code is ``200 OK``.\n",
      " |  \n",
      " |  text\n",
      " |      Content of the response, in unicode.\n",
      " |      \n",
      " |      If Response.encoding is None, encoding will be guessed using\n",
      " |      ``chardet``.\n",
      " |      \n",
      " |      The encoding of the response content is determined based solely on HTTP\n",
      " |      headers, following RFC 2616 to the letter. If you can take advantage of\n",
      " |      non-HTTP knowledge to make a better guess at the encoding, you should\n",
      " |      set ``r.encoding`` appropriately before accessing this property.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __attrs__ = ['_content', 'status_code', 'headers', 'url', 'history', '...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8876a35b-9271-4a52-b400-f7b037fb4ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# streaming chunk size\n",
    "CHUNK_SIZE = 1024\n",
    "\n",
    "XI_API_KEY = \"7b9879f9e2b120bea4cf089b2ae47ef4\"\n",
    "VOICE_SAMPLE_PATH1 = \"<path-to-file>\"\n",
    "VOICE_SAMPLE_PATH2 = \"<path-to-file>\"\n",
    "OUTPUT_PATH = \"<path-to-file>\"\n",
    "\n",
    "add_voice_url = \"https://api.elevenlabs.io/v1/voices/add\"\n",
    "\n",
    "headers = {\n",
    "  \"Accept\": \"application/json\",\n",
    "  \"xi-api-key\": XI_API_KEY\n",
    "}\n",
    "\n",
    "data = {\n",
    "    'name': 'Voice name',\n",
    "    'labels': '{\"accent\": \"American\", \"gender\": \"Female\"}',\n",
    "    'description': 'An old American male voice with a slight hoarseness in his throat. Perfect for news.'\n",
    "}\n",
    "\n",
    "files = [\n",
    "    ('files', ('sample1.mp3', open(VOICE_SAMPLE_PATH1, 'rb'), 'audio/mpeg')),\n",
    "    ('files', ('sample2.mp3', open(VOICE_SAMPLE_PATH2, 'rb'), 'audio/mpeg'))\n",
    "]\n",
    "\n",
    "response = requests.post(add_voice_url, headers=headers, data=data, files=files)\n",
    "voice_id = response.json()[\"voice_id\"]\n",
    "\n",
    "# get default voice settings\n",
    "response = requests.get(\n",
    "    \"https://api.elevenlabs.io/v1/voices/settings/default\",\n",
    "    headers={ \"Accept\": \"application/json\" }\n",
    ").json()\n",
    "stability, similarity_boost = response[\"stability\"], response[\"similarity_boost\"]\n",
    "\n",
    "tts_url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream\"\n",
    "\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "\n",
    "data = {\n",
    "  \"text\": \"Some very long text to be read by the voice\",\n",
    "  \"model_id\": \"eleven_monolingual_v1\",\n",
    "  \"voice_settings\": {\n",
    "    \"stability\": stability,\n",
    "    \"similarity_boost\": similarity_boost\n",
    "  }\n",
    "}\n",
    "\n",
    "response = requests.post(tts_url, json=data, headers=headers, stream=True)\n",
    "\n",
    "with open(OUTPUT_PATH, 'wb') as f:\n",
    "    for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "\n",
    "# Retrieve history. It should contain generated sample.\n",
    "history_url = \"https://api.elevenlabs.io/v1/history\"\n",
    "\n",
    "headers = {\n",
    "  \"Accept\": \"application/json\",\n",
    "  \"xi-api-key\": XI_API_KEY\n",
    "}\n",
    "\n",
    "response = requests.get(history_url, headers=headers)\n",
    "\n",
    "print(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
